{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Secure_And_Private_AI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPx7nSDe6AsmNPv9sgAv+gG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gokulanv/ToyFederatedLearning/blob/master/DifferentialPrivacy/ToyDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PnpH7Ws6jNp",
        "colab_type": "text"
      },
      "source": [
        "# Toy Differential Privacy - Simple Database Queries\n",
        "\n",
        "In this section I understand Differential Privacy in the context of a database query. The database is going to be a VERY simple database with only one boolean column. Each row corresponds to a person. Each value corresponds to whether or not that person has a certain private attribute (such as whether they have a certain disease, or whether they are above/below a certain age). We are then going to learn how to know whether a database query over such a small database is differentially private or not - and more importantly - what techniques are at our disposal to ensure various levels of privacy\n",
        "\n",
        "##First We Create a Simple Database\n",
        "Step one is to create our database - we're going to do this by initializing a random list of 1s and 0s (which are the entries in our database). Note - the number of entries directly corresponds to the number of people in our database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1U3MmHf6bUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34e1c0be-5fa4-46fe-f1d3-1738d3263487"
      },
      "source": [
        "import torch\n",
        "\n",
        "# the number of entries in our database\n",
        "num_entries = 5000\n",
        "\n",
        "db = torch.rand(num_entries) > 0.5\n",
        "db"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True, False,  True,  ..., False, False,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diGOK14C6_Yk",
        "colab_type": "text"
      },
      "source": [
        "# Project: Generate Parallel Databases\n",
        "Key to the definition of differenital privacy is the ability to ask the question \"When querying a database, if I removed someone from the database, would the output of the query be any different?\". Thus, in order to check this, we must construct what we term \"parallel databases\" which are simply databases with one entry removed.\n",
        "\n",
        "In this first project, I create a list of every parallel database to the one currently contained in the \"db\" variable. Then, I create a function which both:\n",
        "\n",
        "\n",
        "*   creates the initial database (db)\n",
        "*   creates all parallel databases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8NBQYTM68Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db = torch.rand(num_entries) > 0.5\n",
        "db = db.int()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TzLeEan7MIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d72f3ac-2f4d-4e8d-a5de-0922327a4fb3"
      },
      "source": [
        "def get_parallel_db(db, remove_index):\n",
        "\n",
        "    return torch.cat((db[0:remove_index], \n",
        "                      db[remove_index+1:])).int()\n",
        "get_parallel_db(db, 10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1,  ..., 1, 1, 0], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39wNRuJu9p6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40c1bf5b-f6e1-4c55-8aea-0ad878a6c53b"
      },
      "source": [
        "len(db), len(get_parallel_db(db, 100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 4999)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eklkDEegFfPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_parallel_dbs(db):\n",
        "\n",
        "    parallel_dbs = list()\n",
        "\n",
        "    for i in range(len(db)):\n",
        "        pdb = get_parallel_db(db, i)\n",
        "        parallel_dbs.append(pdb)\n",
        "    \n",
        "    return parallel_dbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuSomwtnFhgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdbs = get_parallel_dbs(db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP7fcvOLFkn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_db_and_parallels(num_entries):\n",
        "    \n",
        "    db = (torch.rand(num_entries) > 0.5).int()\n",
        "    pdbs = get_parallel_dbs(db)\n",
        "    \n",
        "    return db, pdbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8n8NGAzFpHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCBE9LB8F5w5",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Towards Evaluating The Differential Privacy of a Function\n",
        "Intuitively, we want to be able to query our database and evaluate whether or not the result of the query is leaking \"private\" information. As mentioned previously, this is about evaluating whether the output of a query changes when we remove someone from the database. Specifically, we want to evaluate the maximum amount the query changes when someone is removed (maximum over all possible people who could be removed). So, in order to evaluate how much privacy is leaked, we're going to iterate over each person in the database and measure the difference in the output of the query relative to when we query the entire database.\n",
        "\n",
        "Just for the sake of argument, let's make our first \"database query\" a simple sum. Aka, we're going to count the number of 1s in the database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h1qteyuFvpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFz4aQh_KL-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db):\n",
        "    return db.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3by8MZnKPUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_db_result = query(db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxtc9L0eKIuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sensitivity = 0\n",
        "for pdb in pdbs:\n",
        "    pdb_result = query(pdb)\n",
        "    \n",
        "    db_distance = torch.abs(pdb_result - full_db_result)\n",
        "    \n",
        "    if(db_distance > sensitivity):\n",
        "        sensitivity = db_distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U2yvM3tNC60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9b8cdc7-c07a-42b2-caed-1be46445f2bb"
      },
      "source": [
        "sensitivity"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1TrDNxsNIPG",
        "colab_type": "text"
      },
      "source": [
        "# Project - Evaluating the Privacy of a Function\n",
        "In the last section, we measured the difference between each parallel db's query result and the query result for the entire database and then calculated the max value (which was 1). This value is called \"sensitivity\", and it corresponds to the function we chose for the query. Namely, the \"sum\" query will always have a sensitivity of exactly 1. However, we can also calculate sensitivity for other functions as well.\n",
        "\n",
        "Let's try to calculate sensitivity for the \"mean\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7j7wessNHd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!\n",
        "db, pdbs = create_db_and_parallels(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euXq3N9NNSA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query_mean(db):\n",
        "    return db.float().mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbhlE3nENShN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db_res = query_mean(db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK69C0rLNXMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2d5b75e-99f6-49a3-c357-7e9ad9760a0a"
      },
      "source": [
        "sensitivity =0 \n",
        "for pdb in pdbs:\n",
        "    \n",
        "    pdb_result = query_mean(pdb)\n",
        "    db_distance = torch.abs(pdb_result - db_res)\n",
        "    \n",
        "    if(db_distance > sensitivity):\n",
        "        sensitivity = db_distance\n",
        "\n",
        "sensitivity"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJSGkwxXNqXJ",
        "colab_type": "text"
      },
      "source": [
        "\"Sensitivity\" is measuring how sensitive the output of the query is to a person being removed from the database. For a simple sum, this is always 1, but for the mean, removing a person is going to change the result of the query by rougly 1 divided by the size of the database (which is much smaller). Thus, \"mean\" is a VASTLY less \"sensitive\" function (query) than SUM.\n",
        "\n",
        "# Project: Calculate L1 Sensitivity For Threshold\n",
        "In this first project, I calculate the sensitivty for the \"threshold\" function.\n",
        "\n",
        "First compute the sum over the database (i.e. sum(db)) and return whether that sum is greater than a certain threshold.\n",
        "Then, I create databases of size 10 and threshold of 5 and calculate the sensitivity of the function.\n",
        "Finally, re-initialize the database 10 times and calculate the sensitivity each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gR4-KKNbJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sum(db ,threshold):\n",
        "    return (db.sum() >threshold ).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apnMHI4eN0sD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb1KuMlSN2e2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_sensitivity(n_entries):\n",
        "    db, pdbs = create_db_and_parallels(n_entries)\n",
        "    sensitivity = 0\n",
        "    for pdb in pdbs:\n",
        "        db_sum_result = sum(db, 5)\n",
        "        pdb_response = sum(pdb, 5)\n",
        "        distance = torch.abs(pdb_response - db_sum_result)\n",
        "        if(distance > sensitivity):\n",
        "            sensitivity = distance\n",
        "    return(sensitivity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6U4bMU0N5Dt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d9051f08-4497-4a50-c7f8-b18a17fdc139"
      },
      "source": [
        "for i in range(10):\n",
        "    sens_calculated = calc_sensitivity(10)\n",
        "    print(sens_calculated)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "tensor(1.)\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJkrq8RjOGia",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: A Basic Differencing Attack\n",
        "Sadly none of the functions we've looked at so far are differentially private (despite them having varying levels of sensitivity). The most basic type of attack can be done as follows.\n",
        "\n",
        "Let's say we wanted to figure out a specific person's value in the database. All we would have to do is query for the sum of the entire database and then the sum of the entire database without that person!\n",
        "\n",
        "# Project: Perform a Differencing Attack on Row 5\n",
        "In this project, I construct a database and then demonstrate how we can use two different sum queries to explose the value of the person represented by row 10 in the database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSqJCoAuN6xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(36)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy_WfRG2OPpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdb = get_parallel_db(db, remove_index=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me5cmZXbPNoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6456f6fd-9f8e-49c9-9c85-9c378b8b5b07"
      },
      "source": [
        "db[5]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0, dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8M3olxvOl1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "94feaded-4887-44ba-9793-3cb0115783bf"
      },
      "source": [
        "pdb"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5HXP99OO8xI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b3b3a9d-57eb-4052-a9b7-4a4ec23fe4d4"
      },
      "source": [
        "# Attack using sum query\n",
        "db.sum() - pdb.sum()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1do5IrK6PFgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72aa28c5-4e4c-401c-9728-e35df05d8295"
      },
      "source": [
        "sum(db, 7) - sum(pdb, 5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-cAEAoHPIts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f21668a-424a-4ee7-e82a-85b85517b663"
      },
      "source": [
        "# Attack using mean query\n",
        "db.sum().float()/len(db) - pdb.sum().float()/len(pdb)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0127)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "____EZ7NQWE7",
        "colab_type": "text"
      },
      "source": [
        "If the database represents whether the person has cancer or not, now we can easily know that he has cancer using this differential attack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MKH5zLa7-8F",
        "colab_type": "text"
      },
      "source": [
        "## Project: Local Differential Privacy\n",
        "As you can see, the basic sum query is not differentially private at all! In truth, differential privacy always requires a form of randomness added to the query. Let me show you what I mean.\n",
        "\n",
        "### Randomized Response (Local Differential Privacy)\n",
        "Let's say I have a group of people I wish to survey about a very taboo behavior which I think they will lie about (say, I want to know if they have ever committed a certain kind of crime). I'm not a policeman, I'm just trying to collect statistics to understand the higher level trend in society. So, how do we do this? One technique is to add randomness to each person's response by giving each person the following instructions (assuming I'm asking a simple yes/no question):\n",
        "\n",
        "Flip a coin 2 times. \\\\\n",
        "If the first coin flip is heads, answer honestly \\\\\n",
        "If the first coin flip is tails, answer according to the second coin flip (heads for yes, tails for no)! \\\\\n",
        "\n",
        "Thus, each person is now protected with \"plausible deniability\". If they answer \"Yes\" to the question \"have you committed X crime?\", then it might becasue they actually did, or it might be becasue they are answering according to a random coin flip. Each person has a high degree of protection. Furthermore, we can recover the underlying statistics with some accuracy, as the \"true statistics\" are simply averaged with a 50% probability. Thus, if we collect a bunch of samples and it turns out that 60% of people answer yes, then we know that the TRUE distribution is actually centered around 70%, because 70% averaged wtih 50% (a coin flip) is 60% which is the result we obtained.\n",
        "\n",
        "However, it should be noted that, especially when we only have a few samples, the this comes at the cost of accuracy. This tradeoff exists across all of Differential Privacy. The greater the privacy protection (plausible deniability) the less accurate the results.\n",
        "\n",
        "Let's implement this local DP for our database before!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzHAmn6vQh3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWZd3BAd8Qaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6efcfe4f-edd7-4aeb-fbee-7b0032d723f9"
      },
      "source": [
        "db"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "        1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "        1, 1, 1, 1], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHnFHup58dQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "second_coin_flip = (torch.rand(len(db)) > 0.5).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzvGLlrs8s-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first honest response\n",
        "res1 = db.float() * first_coin_flip\n",
        "\n",
        "# second random response\n",
        "res2 = (1 - first_coin_flip) * second_coin_flip\n",
        "\n",
        "# LDP adds noise to the DB entries\n",
        "augmented_db = res1 + res2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0rXsv6k8Q9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4618f708-eb54-4293-971d-f458a290fe8c"
      },
      "source": [
        "true_mean = torch.mean(db.float())\n",
        "augmented_mean = torch.mean(augmented_db.float())\n",
        "true_mean, augmented_mean"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5400), tensor(0.4900))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSi_o_un9wNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Second response is always skewed by 50%\n",
        "# So, we deskew the results\n",
        "db_result = torch.mean(augmented_db).float() - 2 * 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm2oV5Q_-Dha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db):\n",
        "    first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "    # first honest response\n",
        "    res1 = db.float() * first_coin_flip\n",
        "\n",
        "    # second random response\n",
        "    res2 = (1 - first_coin_flip) * second_coin_flip\n",
        "\n",
        "    # LDP adds noise to the DB entries\n",
        "    augmented_db = res1 + res2\n",
        "    true_mean = torch.mean(db.float())\n",
        "    augmented_mean = torch.mean(augmented_db.float())\n",
        "    db_result = augmented_mean * 2 - 0.5 # deskew\n",
        "\n",
        "    return db_result, true_mean\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t79n5NrE_uGl",
        "colab_type": "text"
      },
      "source": [
        "### LDP Across different data points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ymjVuj2-aHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4819d0f4-91a0-4209-ae58-967a9cbf9195"
      },
      "source": [
        "db, pdbs = create_db_and_parallels(10)\n",
        "query(db)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9000), tensor(0.5000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzdvGANW_h_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a060fcd-1e1f-4a7a-d3ef-2f3cb016db0e"
      },
      "source": [
        "db, pdbs = create_db_and_parallels(100)\n",
        "query(db)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7200), tensor(0.5400))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bdu70Zl_lJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d90dfcc2-236b-4bae-8382-b6ff33bca2d7"
      },
      "source": [
        "db, pdbs = create_db_and_parallels(1000)\n",
        "query(db)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4660), tensor(0.5070))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRz21Flu_n6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f34e7f03-af7c-4c20-e9e8-aeea1443aab8"
      },
      "source": [
        "db, pdbs = create_db_and_parallels(10000)\n",
        "query(db)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4814), tensor(0.4925))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MglzTfRAimT",
        "colab_type": "text"
      },
      "source": [
        "## Varying Amounts of Noise\n",
        "Here, I augment the randomized response query (the one we just wrote) to allow for varying amounts of randomness to be added. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG8oNFYf_pX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db, noise =0.2):\n",
        "    actual_result = torch.mean(db.float())\n",
        "    first_coin_flip = (torch.rand(len(db)) > noise).float()\n",
        "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "    noisy_result = (db.float()* first_coin_flip) + ((1-first_coin_flip )* second_coin_flip)\n",
        "    corrected_db_result = ((torch.mean(noisy_result.float()) /noise) - 0.5)* noise/(1-noise)\n",
        "    return actual_result, corrected_db_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02_78clUYDRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "457a4a21-d631-4442-a3f8-cd0426fd5cbf"
      },
      "source": [
        "db2,pdbs = create_db_and_parallels(5000)\n",
        "actual_result, noisy_result = query(db2)\n",
        "\n",
        "print(\"actual result\" , actual_result)\n",
        "print(\"noisy result\", noisy_result)\n",
        "\n",
        "db2,pdbs = create_db_and_parallels(10000)\n",
        "actual_result, noisy_result = query(db2)\n",
        "\n",
        "print(\"actual result\" , actual_result)\n",
        "print(\"noisy result\", noisy_result)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual result tensor(0.5102)\n",
            "noisy result tensor(0.5125)\n",
            "actual result tensor(0.5030)\n",
            "noisy result tensor(0.5055)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQX6PcdeIL8U",
        "colab_type": "text"
      },
      "source": [
        "## Lesson: How To Add Noise for Global Differential Privacy\n",
        "\n",
        "This method adds noise to the output of our query so that it satisfies a certain epsilon-delta differential privacy threshold.\n",
        "\n",
        "There are two kinds of noise we can add - Gaussian Noise or Laplacian Noise. Generally speaking Laplacian is better, but both are still valid.\n",
        "\n",
        "\n",
        "The amount of noise necessary to add to the output of a query is a function of four things:\n",
        "\n",
        "*  the type of noise (Gaussian/Laplacian)\n",
        "*  the sensitivity of the query/function\n",
        "*  the desired epsilon (ε)\n",
        "*  the desired delta (δ) \\\\\n",
        "\n",
        "Thus, for each type of noise we're adding, we have different way of calculating how much to add as a function of sensitivity, epsilon, and delta. We're going to focus on Laplacian noise. Laplacian noise is increased/decreased according to a \"scale\" parameter b. We choose \"b\" based on the following formula.\n",
        "\n",
        "b = sensitivity(query) / epsilon\n",
        "\n",
        "In other words, if we set b to be this value, then we know that we will have a privacy leakage of <= epsilon. Furthermore, the nice thing about Laplace is that it guarantees this with delta == 0. There are some tunings where we can have very low epsilon where delta is non-zero, but we'll ignore them for now.\n",
        "\n",
        "Querying Repeatedly\n",
        "if we query the database multiple times - we can simply add the epsilons (Even if we change the amount of noise and their epsilons are not the same).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBVnbFCzYJ1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "062fa9cf-7f93-41c7-bd4a-8f709dbab597"
      },
      "source": [
        "epsilon=0.5\n",
        "import numpy as np\n",
        "\n",
        "db, pdbs = create_db_and_parallels(100)\n",
        "\n",
        "def sum_query(db):\n",
        "     return   db.sum()\n",
        "\n",
        "def laplacian_mechanism(db, query, sensitivity):\n",
        "    beta = sensitivity/epsilon\n",
        "    noise = torch.tensor(np.random.laplace(0,beta,1))\n",
        "    return query(db) + noise\n",
        "\n",
        "print(laplacian_mechanism(db,sum_query,1))\n",
        "\n",
        "def mean_query(db):\n",
        "     return torch.mean(db.float())\n",
        "\n",
        "print(laplacian_mechanism(db,mean_query,0.01))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([49.1228], dtype=torch.float64)\n",
            "tensor([0.5323], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SrEM2NK3lRT",
        "colab_type": "text"
      },
      "source": [
        "## An Example Scenario: A Health Neural Network\n",
        "Consider a scenario - I work for a hospital and I have a large collection of images about my patients. However, I don't know what's in them. I would like to use these images to develop a neural network which can automatically classify them, however since my images aren't labeled, they aren't sufficient to train a classifier.\n",
        "\n",
        "I reach out to 10 partner hospitals which DO have annotated data. I hope to train my new classifier on their datasets so that I can automatically label my own. While these hospitals are interested in helping, they have privacy concerns regarding information about their patients. Thus, I will use the following technique to train a classifier which protects the privacy of patients in the other hospitals.\n",
        "\n",
        "1) Ask 10 hospitals to train a model on their own datasets (All of which have the same kinds of labels) \\\\\n",
        "2) Use 10 partner models to predict on my local dataset, generating 10 labels for each datapoint \\\\\n",
        "3) Then, for each local data point (now with 10 labels), I will perform a DP query to generate the final true label. This query is a \"max\" function, where \"max\" is the most frequent label across the 10 labels. I will need to add laplacian noise to make this Differentially Private to a certain epsilon/delta constraint. \\\\\n",
        "4) Finally, I will retrain a new model on the local dataset which now has labels. This will be our final \"DP\" model.\n",
        "\n",
        "So, let's say we have 10,000 training examples, and we've got 10 labels for each example (from our 10 \"teacher models\" which were trained directly on private data). Each label is chosen from a set of 10 possible labels (categories) for each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjgOrc5oIg5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_teachers = 10 # we're working with 10 partner hospitals\n",
        "num_examples = 10000 # the size of OUR dataset\n",
        "num_labels = 10 # number of lablels for our classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ox-6dM130JB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4f395242-de96-4a50-b465-1077e51413ef"
      },
      "source": [
        "preds = (np.random.rand(num_examples, num_teachers) * num_labels).astype(int)# fake predictions\n",
        "\n",
        "print(preds.shape)\n",
        "print(preds)\n",
        "\n",
        "new_labels = list()\n",
        "\n",
        "for an_image in preds:\n",
        "\n",
        "    label_counts = np.bincount(an_image, minlength=num_labels)\n",
        "    epsilon = 0.1\n",
        "    beta = 1 / epsilon\n",
        "\n",
        "    for i in range(len(label_counts)):\n",
        "        label_counts[i] += np.random.laplace(0, beta, 1)\n",
        "\n",
        "    new_label = np.argmax(label_counts)\n",
        "    \n",
        "    new_labels.append(new_label)\n",
        "\n",
        "\n",
        "print('Noisy 10000 labels curated from other hospitals')\n",
        "print(len(new_labels))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "[[4 3 2 ... 1 1 8]\n",
            " [3 8 2 ... 2 9 4]\n",
            " [6 9 0 ... 3 9 7]\n",
            " ...\n",
            " [2 3 4 ... 0 8 2]\n",
            " [0 8 3 ... 2 8 0]\n",
            " [1 7 9 ... 6 9 8]]\n",
            "Noisy 10000 labels curated from other hospitals\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ByqxeSX5t-b",
        "colab_type": "text"
      },
      "source": [
        "## PATE\n",
        "Epsilon cannot be extended by post-processing.\n",
        " *  Generate a dataset with epsilon sensivity and train a deep learning model on this dataset and verify that the sensitivity does not increase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZKyLvWWA9pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install syft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7OsSs114uTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8edb40af-f1f7-4d00-ac57-b8d72dbc5d2a"
      },
      "source": [
        "labels = np.array([9, 9, 3, 6, 9, 9, 9, 2, 8, 9])\n",
        "counts = np.bincount(labels, minlength=10)\n",
        "print(counts)\n",
        "query_result = np.argmax(counts)\n",
        "print(query_result)\n",
        "\n",
        "from syft.frameworks.torch.dp import pate\n",
        "\n",
        "num_teachers, num_examples, num_labels = (100, 100, 10)\n",
        "preds = (np.random.rand(num_teachers, num_examples) * num_labels).astype(int) #fake preds\n",
        "indices = (np.random.rand(num_examples) * num_labels).astype(int) # true answers\n",
        "\n",
        "\n",
        "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=preds, indices=indices, noise_eps=0.1, delta=1e-5)\n",
        "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
        "print(\"Data Dependent Epsilon:\", data_dep_eps)\n",
        "\n",
        "preds[:,0:10] *= 0\n",
        "\n",
        "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=preds, indices=indices, noise_eps=0.1, delta=1e-5)\n",
        "\n",
        "assert data_dep_eps < data_ind_eps\n",
        "\n",
        "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
        "print(\"Data Dependent Epsilon:\", data_dep_eps)\n",
        "\n",
        "preds[:,0:50] *= 0\n",
        "\n",
        "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=preds, indices=indices, noise_eps=0.1, delta=1e-5, moments=20)\n",
        "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
        "print(\"Data Dependent Epsilon:\", data_dep_eps)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 1 0 0 1 0 1 6]\n",
            "9\n",
            "Data Independent Epsilon: 11.756462732485115\n",
            "Data Dependent Epsilon: 11.756462732485105\n",
            "Warning: May not have used enough values of l. Increase 'moments' variable and run again.\n",
            "Data Independent Epsilon: 11.756462732485115\n",
            "Data Dependent Epsilon: 1.52655213289881\n",
            "Data Independent Epsilon: 11.756462732485115\n",
            "Data Dependent Epsilon: 0.9029013677789843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI_6Q2KRAvjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_cg249DXsWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}